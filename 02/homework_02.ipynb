{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf75ab4-bd4d-4ec2-a708-74797dbfce44",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - regrese\n",
    "\n",
    "* Termíny jsou uvedeny na [courses.fit.cvut.cz](https://courses.fit.cvut.cz/BI-ML1/homeworks/index.html).\n",
    "* Pokud odevzdáte úkol po prvním termínu ale před nejzazším termínem, budete penalizování -12 body, pozdější odevzdání je bez bodu.\n",
    "* V rámci tohoto úkolu se musíte vypořádat s regresní úlohou, s příznaky různých typů a s chybějícími hodnotami.\n",
    "* Před tím, než na nich postavíte predikční model, je třeba je nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "Využívejte buňky typu `Markdown` k vysvětlování Vašeho postupu. Za nepřehlednost budeme strhávat body.\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí délky dožití v různých zemích a letech.\n",
    "K dispozici máte trénovací data v souboru `data.csv` a data na vyhodnocení v souboru `evaluation.csv`.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "\n",
    "* Year - Rok\n",
    "* Status - Status rozvinuté nebo rozvojové země\n",
    "* Life expectancy - Délka dožití v letech - **cílová proměnná, kterou budete predikovat**\n",
    "* Adult Mortality - Úmrtnost dospělých bez ohledu na pohlaví (pravděpodobnost, že osoby, které dosáhly věku 15 let, zemřou před dosažením věku 60 let (uvedeno na 1 000 osob)).\n",
    "* infant deaths - počet zemřelých kojenců na 1000 obyvatel\n",
    "* Alcohol - Alkohol, zaznamenaná spotřeba na obyvatele (15+) (v litrech čistého alkoholu)\n",
    "* percentage expenditure - Výdaje na zdravotnictví v procentech hrubého domácího produktu na obyvatele (%)\n",
    "* Hepatitis B - pokrytí očkováním proti hepatitidě B (HepB) u dětí ve věku 1 roku (%)\n",
    "* Measles - Spalničky - počet hlášených případů na 1000 obyvatel\n",
    "* BMI - průměrný index tělesné hmotnosti celé populace\n",
    "* under-five deaths - počet úmrtí dětí do pěti let na 1000 obyvatel\n",
    "* Polio - proočkovanost proti dětské obrně (Pol3) u dětí ve věku 1 roku (%)\n",
    "* Total expenditure - Výdaje vládních institucí na zdravotnictví jako procento celkových vládních výdajů (%)\n",
    "* Diphtheria - pokrytí očkováním proti záškrtu, tetanu a černému kašli (DTP3) u jednoletých dětí (%)\n",
    "* HIV/AIDS - počet úmrtí na 1 000 živě narozených dětí na HIV/AIDS (0-4 roky)\n",
    "* GDP - hrubý domácí produkt na obyvatele (v USD)\n",
    "* Population - počet obyvatel země\n",
    "* thinness 1-19 years - podíl dětí ve věku 10-19 let s indexem tělesné hmotnosti (BMI) menším než 2 směrodatné odchylky pod mediánem (%)\n",
    "* thinness 5-9 years - podíl dětí ve věku 5-9 let s indexem tělesné hmotnosti (BMI) menším než 2 směrodatné odchylky pod mediánem (%)\n",
    "* Income composition of resources - Index lidského rozvoje z hlediska příjmového složení zdrojů (index v rozmezí 0 až 1)\n",
    "* Schooling - počet let školní docházky (roky)\n",
    "\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Body zadání**, za jejichž (poctivé) vypracování získáte **25 bodů**: \n",
    "  * V notebooku načtěte data ze souboru `data.csv`. Vhodným způsobem si je rozdělte na podmnožiny, které Vám poslouží pro trénování (trénovací), porovnávání modelů (validační) a následnou predikci výkonnosti finálního modelu (testovací).\n",
    "    \n",
    "  * Proveďte základní předzpracování dat:\n",
    "    * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném regresním modelu.\n",
    "    * Nějakým způsobem se vypořádejte s chybějícími hodnotami. _Pozor na metodické chyby!_\n",
    "    * Můžete využívat i vizualizace. Vše stručně ale náležitě komentujte.\n",
    "<br /><br />\n",
    "  * Vytvořte **vlastní implementaci náhodného lesa**. Použijte k tomu níže předpřipravenou kostru.\n",
    "  \n",
    "  * Na připravená data postupně aplikujte Vaši předchozí implementaci modelu náhodného lesa, dále jeden z modelů **lineární regrese** nebo **hřebenové regrese**, a alespoň jeden další model podle Vašeho uvážení, přičemž pro každý z těchto modelů přiměřeně:\n",
    "    * Okomentujte vhodnost daného modelu pro daný typ úlohy.\n",
    "    * Experimentujte s normalizací (standardizace/min-max), pokud pro daný model očekáváte její příznivý vliv.\n",
    "    * Vyberte si hlavní hyperparametry k ladění a najděte jejich nejlepší hodnoty (vzhledem k RMSE).\n",
    "    * Pro model s nejlepšími hodnotami hyperparametrů určete jeho chybu pomocí RMSE a MAE. _Pozor na metodické chyby!_\n",
    "    * Získané výsledky vždy řádně okomentujte.\n",
    "<br /><br />\n",
    "  * Ze všech zkoušených možností v předchozím kroku vyberte finální model a odhadněte, jakou chybu (RMSE) můžete očekávat na nových datech, která jste doposud neměli k dispozici. _Pozor na metodické chyby!_\n",
    "    \n",
    "  * Nakonec načtěte vyhodnocovací data ze souboru `evaluation.csv`. Pomocí finálního modelu napočítejte predikce pro tato data. Vytvořte soubor `results.csv`, ve kterém získané predikce uložíte s využitím tří sloupců: **Country**, **Year** a **Life expectancy**. Tento soubor též odevzdejte (uložte do repozitáře vedle notebooku).\n",
    "\n",
    "  * Ukázka prvních řádků souboru `results.csv`:\n",
    "  \n",
    "```\n",
    "Country,Year,Life expectancy\n",
    "Peru,2012,71.4\n",
    "Peru,2013,72.6\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-ML1/homeworks/index.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "280dc5d5-087b-4060-bd0a-c950c91f0533",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T23:43:10.396436Z",
     "start_time": "2023-12-09T23:43:10.361584300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Váš kód zde\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "\n",
    "########################################################\n",
    "# Předpřipravená kostra modelu náhodného lesa\n",
    "class CustomRandomForest:\n",
    "    \"\"\"\n",
    "    Třída Vašeho modelu\n",
    "    Bude se jednat o model náhodného lesa, kde podmodely tvoří rozhodovací stromy pro regresi.\n",
    "    Pro podmodely můžete použít implementaci DecisionTreeRegressor ze sklearn.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators, max_samples, max_depth, **kwargs):\n",
    "        \"\"\"\n",
    "        Konstruktor modelu\n",
    "        Základní hyperparametery:\n",
    "            n_estimators - počet podmodelů - rozhodovacích stromů.\n",
    "            max_samples - vyberte si, zda tento parametr bude označovat relativní počet bodů (tj. číslo mezi 0 a 1) \n",
    "                          nebo absolutní počet bodů (tj. číslo mezi 1 a velikostí trénovací množiny), \n",
    "                          které budou pro každý podmodel rozhodovacího stromu náhodně vybrány z trénovací množiny (bootstrap) a použity k jeho trénování.\n",
    "            max_depth - maximální hloubka každého z podmodelů rozhodovacího stromu.\n",
    "            kwargs - (volitelně) případné další hyperparametry, které pošlete do podmodelů rozhodovacího stromu\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_samples = max_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.kwargs = kwargs\n",
    "        self.models = []\n",
    "        self.random_seed = 666\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Natrénování modelu. Trénovací data jsou v argumentech X a y.\n",
    "        Pro trénování podmodelů používejte bootstraping a velikost samplovaného vzorku vezměte z hyperparametru max_samples_fraction\n",
    "        \"\"\"\n",
    "        for _ in range(self.n_estimators):\n",
    "            #selected_indexes = np.random.choice(X.shape[0], size=self.max_samples, replace=True) # get random indexes of max_samples size that #could repeat \n",
    "\n",
    "           # selected_indexes = np.intersect1d(selected_indexes, np.arange(X.shape[0]))\n",
    "\n",
    "            #if len(selected_indexes) == 0:\n",
    "            # If no valid indexes are selected, skip this iteration\n",
    "             #   continue\n",
    "            \n",
    "            X_selected = X.sample(n=self.max_samples, replace=True, random_state=self.random_seed)\n",
    "            y_selected = y.sample(n=self.max_samples, replace=True, random_state=self.random_seed)\n",
    "            \n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X_selected, y_selected)\n",
    "            \n",
    "            self.models.append(tree)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predikce y v zadaných bodech X\n",
    "        \"\"\"\n",
    "        ypredicted = np.zeros((X.shape[0],))\n",
    "        \n",
    "        for tree in self.models:\n",
    "            ypredicted += tree.predict(X) # add 1 or 0 from each tree in forest\n",
    "        \n",
    "        y_predicted /= self.n_estimators # get real prediction from all trees\n",
    "        return ypredicted\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_estimators': self.n_estimators, 'max_samples': self.max_samples, 'max_depth': self.max_depth, **self.kwargs}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8216231d-137d-4a04-b8f8-5e088e6ac6bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:16.093188400Z",
     "start_time": "2023-12-09T22:55:16.061120Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "X = data.drop('Life expectancy', axis=1)\n",
    "y = data['Life expectancy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "random_seed = 666\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.25, random_state=random_seed)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain, Ytrain, test_size=0.25, random_state=random_seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:16.497688500Z",
     "start_time": "2023-12-09T22:55:16.482578300Z"
    }
   },
   "id": "9871d5cc8091a63a"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velikost trénovací množiny: 1528\n",
      "Velikost validační množiny: 510\n",
      "Velikost testovací množiny: 680\n"
     ]
    }
   ],
   "source": [
    "print(\"Velikost trénovací množiny:\", len(Xtrain))\n",
    "print(\"Velikost validační množiny:\", len(Xval))\n",
    "print(\"Velikost testovací množiny:\", len(Xtest))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:16.895810400Z",
     "start_time": "2023-12-09T22:55:16.884981400Z"
    }
   },
   "id": "9c61f0b11c8b61be"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1528 entries, 2028 to 209\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Country                          1528 non-null   object \n",
      " 1   Year                             1528 non-null   int64  \n",
      " 2   Status                           1528 non-null   object \n",
      " 3   Adult Mortality                  1528 non-null   float64\n",
      " 4   infant deaths                    1528 non-null   int64  \n",
      " 5   Alcohol                          1453 non-null   float64\n",
      " 6   percentage expenditure           1528 non-null   float64\n",
      " 7   Hepatitis B                      1227 non-null   float64\n",
      " 8   Measles                          1528 non-null   int64  \n",
      " 9   BMI                              1513 non-null   float64\n",
      " 10  under-five deaths                1528 non-null   int64  \n",
      " 11  Polio                            1522 non-null   float64\n",
      " 12  Total expenditure                1431 non-null   float64\n",
      " 13  Diphtheria                       1522 non-null   float64\n",
      " 14  HIV/AIDS                         1528 non-null   float64\n",
      " 15  GDP                              1298 non-null   float64\n",
      " 16  Population                       1187 non-null   float64\n",
      " 17  thinness  1-19 years             1513 non-null   float64\n",
      " 18  thinness 5-9 years               1513 non-null   float64\n",
      " 19  Income composition of resources  1445 non-null   float64\n",
      " 20  Schooling                        1445 non-null   float64\n",
      "dtypes: float64(15), int64(4), object(2)\n",
      "memory usage: 262.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype sloupců s null hodnotami:\n",
      "Alcohol                            float64\n",
      "Hepatitis B                        float64\n",
      "BMI                                float64\n",
      "Polio                              float64\n",
      "Total expenditure                  float64\n",
      "Diphtheria                         float64\n",
      "GDP                                float64\n",
      "Population                         float64\n",
      "thinness  1-19 years               float64\n",
      "thinness 5-9 years                 float64\n",
      "Income composition of resources    float64\n",
      "Schooling                          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "display(Xtrain.info())\n",
    "columns_with_null = data.columns[data.isnull().any()].tolist()\n",
    "columns_with_null_dtype = data[data.columns[data.isnull().any()]].dtypes\n",
    "# print(\"Sloupce s null hodnotami:\", columns_with_null)\n",
    "print(\"Dtype sloupců s null hodnotami:\")\n",
    "print(columns_with_null_dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:17.481370600Z",
     "start_time": "2023-12-09T22:55:17.463899400Z"
    }
   },
   "id": "c6947ce95e0fb108"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def replace_nan_mean(dataset, column):\n",
    "    # get mean values depending on training data a fill NaN with mean of this current country to get accurate value as possible\n",
    "    # because for example alcohol in Czech republic and muslim country will not be as accurate as it could have been\n",
    "    # if country whole column is null then replace it with mean from whole train data in this column\n",
    "    \n",
    "    mean_values = Xtrain.groupby('Country')[column].mean()\n",
    "    overall_mean = Xtrain[column].mean()\n",
    "    \n",
    "    for country, mean_value in mean_values.items():\n",
    "        if not pd.isnull(mean_value):\n",
    "            mask = (dataset['Country'] == country) & (dataset[column].isnull())\n",
    "            dataset.loc[mask, column] = mean_value\n",
    "        else:\n",
    "            mask = (dataset['Country'] == country) & (dataset[column].isnull())\n",
    "            dataset.loc[mask, column] = overall_mean\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:18.363974800Z",
     "start_time": "2023-12-09T22:55:18.345503400Z"
    }
   },
   "id": "a927627f0d52d8ba"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "for column_with_null in columns_with_null:\n",
    "    replace_nan_mean(Xtrain, column_with_null)\n",
    "\n",
    "for column_with_null in columns_with_null:\n",
    "    replace_nan_mean(Xval, column_with_null)\n",
    "    \n",
    "for column_with_null in columns_with_null:\n",
    "    replace_nan_mean(Xtest, column_with_null)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:21.490922300Z",
     "start_time": "2023-12-09T22:55:19.045638700Z"
    }
   },
   "id": "3114d962f9e0c5b8"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1528 entries, 2028 to 209\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Country                          1528 non-null   object \n",
      " 1   Year                             1528 non-null   int64  \n",
      " 2   Status                           1528 non-null   object \n",
      " 3   Adult Mortality                  1528 non-null   float64\n",
      " 4   infant deaths                    1528 non-null   int64  \n",
      " 5   Alcohol                          1528 non-null   float64\n",
      " 6   percentage expenditure           1528 non-null   float64\n",
      " 7   Hepatitis B                      1528 non-null   float64\n",
      " 8   Measles                          1528 non-null   int64  \n",
      " 9   BMI                              1528 non-null   float64\n",
      " 10  under-five deaths                1528 non-null   int64  \n",
      " 11  Polio                            1528 non-null   float64\n",
      " 12  Total expenditure                1528 non-null   float64\n",
      " 13  Diphtheria                       1528 non-null   float64\n",
      " 14  HIV/AIDS                         1528 non-null   float64\n",
      " 15  GDP                              1528 non-null   float64\n",
      " 16  Population                       1528 non-null   float64\n",
      " 17  thinness  1-19 years             1528 non-null   float64\n",
      " 18  thinness 5-9 years               1528 non-null   float64\n",
      " 19  Income composition of resources  1528 non-null   float64\n",
      " 20  Schooling                        1528 non-null   float64\n",
      "dtypes: float64(15), int64(4), object(2)\n",
      "memory usage: 262.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 510 entries, 113 to 1864\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Country                          510 non-null    object \n",
      " 1   Year                             510 non-null    int64  \n",
      " 2   Status                           510 non-null    object \n",
      " 3   Adult Mortality                  510 non-null    float64\n",
      " 4   infant deaths                    510 non-null    int64  \n",
      " 5   Alcohol                          510 non-null    float64\n",
      " 6   percentage expenditure           510 non-null    float64\n",
      " 7   Hepatitis B                      510 non-null    float64\n",
      " 8   Measles                          510 non-null    int64  \n",
      " 9   BMI                              510 non-null    float64\n",
      " 10  under-five deaths                510 non-null    int64  \n",
      " 11  Polio                            510 non-null    float64\n",
      " 12  Total expenditure                510 non-null    float64\n",
      " 13  Diphtheria                       510 non-null    float64\n",
      " 14  HIV/AIDS                         510 non-null    float64\n",
      " 15  GDP                              510 non-null    float64\n",
      " 16  Population                       510 non-null    float64\n",
      " 17  thinness  1-19 years             510 non-null    float64\n",
      " 18  thinness 5-9 years               510 non-null    float64\n",
      " 19  Income composition of resources  510 non-null    float64\n",
      " 20  Schooling                        510 non-null    float64\n",
      "dtypes: float64(15), int64(4), object(2)\n",
      "memory usage: 87.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Xtrain.info())\n",
    "display(Xval.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:22.332549800Z",
     "start_time": "2023-12-09T22:55:22.308658900Z"
    }
   },
   "id": "a024963cc1dfbfe"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "X_train_encoded = pd.get_dummies(Xtrain, columns=['Status'], drop_first=True)\n",
    "X_val_encoded = pd.get_dummies(Xval, columns=['Status'], drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(Xtest, columns=['Status'], drop_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:55:23.530140900Z",
     "start_time": "2023-12-09T22:55:23.505205Z"
    }
   },
   "id": "29c86e3eae1e706a"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1528 entries, 2028 to 209\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Country                          1528 non-null   object \n",
      " 1   Year                             1528 non-null   int64  \n",
      " 2   Adult Mortality                  1528 non-null   float64\n",
      " 3   infant deaths                    1528 non-null   int64  \n",
      " 4   Alcohol                          1528 non-null   float64\n",
      " 5   percentage expenditure           1528 non-null   float64\n",
      " 6   Hepatitis B                      1528 non-null   float64\n",
      " 7   Measles                          1528 non-null   int64  \n",
      " 8   BMI                              1528 non-null   float64\n",
      " 9   under-five deaths                1528 non-null   int64  \n",
      " 10  Polio                            1528 non-null   float64\n",
      " 11  Total expenditure                1528 non-null   float64\n",
      " 12  Diphtheria                       1528 non-null   float64\n",
      " 13  HIV/AIDS                         1528 non-null   float64\n",
      " 14  GDP                              1528 non-null   float64\n",
      " 15  Population                       1528 non-null   float64\n",
      " 16  thinness  1-19 years             1528 non-null   float64\n",
      " 17  thinness 5-9 years               1528 non-null   float64\n",
      " 18  Income composition of resources  1528 non-null   float64\n",
      " 19  Schooling                        1528 non-null   float64\n",
      " 20  Status_Developing                1528 non-null   bool   \n",
      "dtypes: bool(1), float64(15), int64(4), object(1)\n",
      "memory usage: 252.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_encoded.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T22:57:33.164249200Z",
     "start_time": "2023-12-09T22:57:33.144581800Z"
    }
   },
   "id": "2ec0c3b106b9a128"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  ParameterGrid\n",
    "\"\"\"\n",
    "tree_param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "forest_param_grid = {\n",
    "    'n_estimators': range(5, 50, 5),\n",
    "    'max_depth': range(3, 15),\n",
    "    'max_samples': range(1, len(X_train_encoded), 50),\n",
    "    **tree_param_grid\n",
    "}\n",
    "\n",
    "param_combinations = list(ParameterGrid(forest_param_grid))\n",
    "\"\"\"\n",
    "\n",
    "n_estimators_values = range(5, 50, 5)\n",
    "max_depth_values = range(3, 15)\n",
    "max_samples_values = range(1, len(X_train_encoded), 50)\n",
    "best_score = float('inf')  # Initialize with a high value\n",
    "best_params = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:36:44.839128500Z",
     "start_time": "2023-12-09T23:36:44.816166200Z"
    }
   },
   "id": "7a838092ce86bb07"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Paraguay'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[106], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m max_samples \u001B[38;5;129;01min\u001B[39;00m max_samples_values:\n\u001B[0;32m      4\u001B[0m     model \u001B[38;5;241m=\u001B[39m CustomRandomForest(n_estimators\u001B[38;5;241m=\u001B[39mn_estimators, max_depth\u001B[38;5;241m=\u001B[39mmax_depth, max_samples\u001B[38;5;241m=\u001B[39mmax_samples)\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_encoded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mYtrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_val_encoded)\n\u001B[0;32m      7\u001B[0m     mse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_val, y_pred)\n",
      "Cell \u001B[1;32mIn[105], line 49\u001B[0m, in \u001B[0;36mCustomRandomForest.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     46\u001B[0m y_selected \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39msample(n\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_samples, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrandom_seed)\n\u001B[0;32m     48\u001B[0m tree \u001B[38;5;241m=\u001B[39m DecisionTreeRegressor(max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_depth)\n\u001B[1;32m---> 49\u001B[0m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_selected\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_selected\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels\u001B[38;5;241m.\u001B[39mappend(tree)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1148\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1149\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1150\u001B[0m     )\n\u001B[0;32m   1151\u001B[0m ):\n\u001B[1;32m-> 1152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001B[0m, in \u001B[0;36mDecisionTreeRegressor.fit\u001B[1;34m(self, X, y, sample_weight, check_input)\u001B[0m\n\u001B[0;32m   1290\u001B[0m \u001B[38;5;129m@_fit_context\u001B[39m(prefer_skip_nested_validation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1292\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001B[39;00m\n\u001B[0;32m   1293\u001B[0m \n\u001B[0;32m   1294\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1317\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m   1318\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1320\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1322\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1323\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1324\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1325\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:242\u001B[0m, in \u001B[0;36mBaseDecisionTree._fit\u001B[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001B[0m\n\u001B[0;32m    238\u001B[0m check_X_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[0;32m    239\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mDTYPE, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, force_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    240\u001B[0m )\n\u001B[0;32m    241\u001B[0m check_y_params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 242\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate_separately\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcheck_X_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck_y_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    244\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    246\u001B[0m missing_values_in_feature_mask \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    247\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_missing_values_in_feature_mask(X)\n\u001B[0;32m    248\u001B[0m )\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(X):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:617\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    615\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m check_X_params:\n\u001B[0;32m    616\u001B[0m     check_X_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdefault_check_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_X_params}\n\u001B[1;32m--> 617\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_X_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m check_y_params:\n\u001B[0;32m    619\u001B[0m     check_y_params \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdefault_check_params, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params}\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:836\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    831\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pandas_requires_conversion:\n\u001B[0;32m    832\u001B[0m     \u001B[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001B[39;00m\n\u001B[0;32m    833\u001B[0m     \u001B[38;5;66;03m# nans\u001B[39;00m\n\u001B[0;32m    834\u001B[0m     \u001B[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001B[39;00m\n\u001B[0;32m    835\u001B[0m     new_dtype \u001B[38;5;241m=\u001B[39m dtype_orig \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m dtype\n\u001B[1;32m--> 836\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43marray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    837\u001B[0m     \u001B[38;5;66;03m# Since we converted here, we do not need to convert again later\u001B[39;00m\n\u001B[0;32m    838\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6530\u001B[0m     results \u001B[38;5;241m=\u001B[39m [ser\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy) \u001B[38;5;28;01mfor\u001B[39;00m _, ser \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()]\n\u001B[0;32m   6532\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6533\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6534\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6535\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor_from_mgr(new_data, axes\u001B[38;5;241m=\u001B[39mnew_data\u001B[38;5;241m.\u001B[39maxes)\n\u001B[0;32m   6536\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    411\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    412\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 414\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    418\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    419\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_cow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    420\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 354\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    355\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    357\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow)\u001B[0m\n\u001B[0;32m    596\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[0;32m    598\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[0;32m    613\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    614\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[1;32m--> 616\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    618\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    620\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    235\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 238\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    242\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    180\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 183\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_astype_nansafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001B[0m, in \u001B[0;36m_astype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    132\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m dtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m    133\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[1;32m--> 134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'Paraguay'"
     ]
    }
   ],
   "source": [
    "for n_estimators in n_estimators_values:\n",
    "    for max_depth in max_depth_values:\n",
    "        for max_samples in max_samples_values:\n",
    "            model = CustomRandomForest(n_estimators=n_estimators, max_depth=max_depth, max_samples=max_samples)\n",
    "            model.fit(X_train_encoded, Ytrain)\n",
    "            y_pred = model.predict(X_val_encoded)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "            # Update the best model if the current one has a lower MSE\n",
    "            if mse < best_score:\n",
    "                best_score = mse\n",
    "                best_params = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_samples': max_samples}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T23:43:15.401149900Z",
     "start_time": "2023-12-09T23:43:14.378434500Z"
    }
   },
   "id": "424742abd2c9fc95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "73cd90e3e02af1f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
